{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97467525",
   "metadata": {},
   "outputs": [],
   "source": [
    "import resources.workspace as ws\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy.random as rnd\n",
    "import scipy.linalg as sla\n",
    "from mpl_tools.misc import nRowCol\n",
    "from mpl_tools.place import freshfig\n",
    "\n",
    "plt.ion();\n",
    "rnd.seed(3000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d326768",
   "metadata": {},
   "source": [
    "# Spatial statistics (\"geostatistics\")\n",
    "\n",
    "Covariances between two (or a few) variables is very well,\n",
    "but if you have not seen it before, the connection between covariances\n",
    "and geophysical (spatial) fields may not be obvious.\n",
    "The purpose of this tutorial is to familiarise you with random (spatial) fields\n",
    "and their estimation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff23e7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid1D = np.linspace(0, 1, 61)\n",
    "N = 15  # ensemble size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532e6d12",
   "metadata": {},
   "source": [
    "## Variograms\n",
    "The \"Variogram\" of a field is essentially `1 - autocovariance`. Thus, it describes the spatial dependence of the field. The mean (1st moment) of a field is usually estimated and described/parametrized with trend lines/surfaces, while higher moments are usually not worth modelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94140fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def variogram(dists, Range=1, kind=\"Gauss\", nugget=0):\n",
    "    \"\"\"Compute variogram for distance points `dists`.\"\"\"\n",
    "    dists = dists / Range\n",
    "    if kind == \"Spheric\":\n",
    "        gamma = 1.5 * dists - .5 * dists**3\n",
    "        gamma[dists >= 1] = 1\n",
    "    elif kind == \"Expo\":\n",
    "        dists *= 3  # by convention\n",
    "        gamma = 1 - np.exp(-dists)\n",
    "    else:  # \"Gauss\"\n",
    "        dists *= 3  # by convention\n",
    "        gamma = 1 - np.exp(-(dists)**2)\n",
    "    # Include nugget (discontinuity at 0)\n",
    "    gamma *= (1-nugget)\n",
    "    gamma[dists != 0] += nugget\n",
    "    return gamma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d3770c",
   "metadata": {},
   "source": [
    "#### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c3d7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ws.interact(Range=(.01, 4), nugget=(0.0, 1, .1))\n",
    "def plot_variogram(Range=1, nugget=0):\n",
    "    fig, ax = freshfig(\"Variograms\")  # fig = plt.figure(figsize=(6, 4))\n",
    "    ax.grid()\n",
    "    ax.set_xlim(0, 1)\n",
    "    ax.set_ylim(0, 1)\n",
    "    for i, kind in enumerate([\"Spheric\", \"Expo\", \"Gauss\"]):\n",
    "        gamma = variogram(grid1D, Range, kind, nugget=nugget)\n",
    "        ax.plot(grid1D, gamma, lw=2, color=f\"C{i}\", label=kind)\n",
    "        ax.legend(loc=\"upper left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b5884c",
   "metadata": {},
   "source": [
    "## Random fields (1D)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6dc2ae4",
   "metadata": {},
   "source": [
    "In order to apply the variogram we must be able to compute the distances between sets (A, B) of points. The following is a fairly efficient implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe95c21",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def dist_euclid(A, B):\n",
    "    \"\"\"Compute $ d_ij = \\| a_i - b_j \\|_2 $ for `a_i in A` and `b_j in B`.\"\"\"\n",
    "    diff = A[:, None, :] - B\n",
    "    d2 = np.sum(diff**2, axis=-1)\n",
    "    return np.sqrt(d2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2784edd",
   "metadata": {},
   "source": [
    "Gaussian random variables (vectors) are fully specified by their mean and covariance.\n",
    "We can use the above variogram function to define the covariance (matrix) between points,\n",
    "by first computing the distances between them.\n",
    "Once in posession of a covariance matrix, we can use it to sample random variables\n",
    "by multiplying its cholesky factor (square root) onto standard normal variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48b7716",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_fields(coords, **vg_params):\n",
    "    \"\"\"Gen. random (Gaussian) fields at `coords` (no structure/ordering required).\"\"\"\n",
    "    dists = dist_euclid(coords, coords)\n",
    "    covar = 1 - variogram(dists, **vg_params)\n",
    "    cholL = sla.cholesky(covar).T\n",
    "    fields = cholL @ rnd.randn(len(coords), N)\n",
    "    return fields"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5902f71d",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "#### Exc:\n",
    "Use the plotting functionality below to\n",
    "explain the effect of `Range` and `nugget`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b793588",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = freshfig(\"1D random fields\")\n",
    "fields = gaussian_fields(grid1D[:, None], Range=1, kind=\"Gauss\", nugget=1e-3)\n",
    "ax.plot(grid1D, fields, lw=2);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65be4518",
   "metadata": {},
   "source": [
    "## Random fields (2D)\n",
    "The following sets up a 2d grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cae0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid2x, grid2y = np.meshgrid(grid1D, grid1D)\n",
    "grid2x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553e8ce6",
   "metadata": {},
   "source": [
    "where `grid2y` has the same shape.\n",
    "\n",
    "However, in the following we will \"flatten\" (a.k.a.\"(un)ravel\", \"vectorize\", or \"string out\") this explicitly 2D grid of nodes into a simple list of points in 2D. Importantly, none of the following methods actually assume any structure to the list. So we could also work with a completely irregularly spaced set of points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f73e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid2D = np.dstack([grid2x, grid2y]).reshape((-1, 2))\n",
    "grid2D.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f16ff08",
   "metadata": {},
   "source": [
    "For example, `gaussian_fields` is immediately applicable also to this 2D case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20809ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "vg_params = dict(Range=1, kind=\"Gauss\", nugget=1e-4)\n",
    "fields = gaussian_fields(grid2D, **vg_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75bebf58",
   "metadata": {},
   "source": [
    "Of course, for plotting purposes, we undo the flattening."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d444b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contour_plot(ax, field, cmap=\"nipy_spectral\", levels=12, has_obs=True):\n",
    "    field = field.reshape(grid2x.shape)  # undo flattening\n",
    "    if has_obs:\n",
    "        ax.plot(*obs_coo.T, \"ko\", ms=4)\n",
    "        ax.plot(*obs_coo.T, \"yo\", ms=1)\n",
    "    ax.set(aspect=\"equal\", xticks=[0, 1], yticks=[0, 1])\n",
    "    return ax.contourf(field, levels=levels, extent=(0, 1, 0, 1),\n",
    "                       cmap=cmap, vmin=vmin, vmax=vmax)\n",
    "\n",
    "# Fix the color scale for all subsequent `contour_plot`.\n",
    "# Use `None` to re-compute the color scale for each subplot.\n",
    "vmin = fields.min()\n",
    "vmax = fields.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c7a2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = freshfig(num=\"2D random fields\", figsize=(5, 4),\n",
    "                    nrows=3, ncols=4, sharex=True, sharey=True)\n",
    "\n",
    "for ax, field in zip(axs.ravel(), fields.T):\n",
    "    contour_plot(ax, field, has_obs=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca58a81",
   "metadata": {},
   "source": [
    "## Estimation problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b65de9a",
   "metadata": {},
   "source": [
    "For our estimation target we will use one of the above generated random fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9412506c",
   "metadata": {},
   "outputs": [],
   "source": [
    "truth = fields.T[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2ead0d",
   "metadata": {},
   "source": [
    "For the observations, we pick some random grid locations for simplicity\n",
    "(even though the methods work also with observations not on grid nodes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9423dfd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nObs = 10\n",
    "obs_idx = rnd.randint(0, len(grid2D), nObs)\n",
    "obs_coo = grid2D[obs_idx]\n",
    "observations = truth[obs_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df253664",
   "metadata": {},
   "source": [
    "## Spatial interpolant methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d33d6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-compute re-used objects\n",
    "dists_yy = dist_euclid(obs_coo, obs_coo)\n",
    "dists_xy = dist_euclid(grid2D, obs_coo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4e1752",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "estims = dict(Truth=truth)\n",
    "vmin=truth.min()\n",
    "vmax=truth.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886fecd7",
   "metadata": {},
   "source": [
    "The cells below contain snippets of different spatial interpolation methods\n",
    "Complete the code snippets below.\n",
    "Test your implementation by running the plotting code in the cell further below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37503202",
   "metadata": {},
   "source": [
    "#### Exc: Nearest neighbour interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46442b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nearest_obs = np.argmin(dists_xy, 1)\n",
    "estims[\"Nearest-n.\"] = observations[nearest_obs]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8367fb",
   "metadata": {},
   "source": [
    "#### Exc: Inverse distance weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a0bb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "expo = 3\n",
    "with np.errstate(invalid='ignore', divide='ignore'):\n",
    "    weights = 1/dists_xy**expo\n",
    "    weights = weights / weights.sum(axis=1, keepdims=True)  # normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29aac307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply weights\n",
    "estims[\"Inv-dist.\"] = weights @ observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e81fe57",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Fix singularities\n",
    "estims[\"Inv-dist.\"][obs_idx] = observations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61674ce",
   "metadata": {},
   "source": [
    "#### Exc: Simple Kriging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7603e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hint: use `sla.solve` or `sla.inv` (less recommended)\n",
    "covar_yy = 1 - variogram(dists_yy, **vg_params)\n",
    "cross_xy = 1 - variogram(dists_xy, **vg_params)\n",
    "regression_coefficients = sla.solve(covar_yy, cross_xy.T).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7728982",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "estims[\"Kriging\"] = regression_coefficients @ observations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3749314a",
   "metadata": {},
   "source": [
    "### Plot truth, estimates, error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b38809f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = freshfig(num=\"Estimation problem\", figsize=(8, 4), squeeze=False,\n",
    "                    nrows=2, ncols=len(estims), sharex=True, sharey=True)\n",
    "\n",
    "for name, ax1, ax2 in zip(estims, *axs):\n",
    "    ax1.set_title(name)\n",
    "    c1 = contour_plot(ax1, estims[name])\n",
    "    c2 = contour_plot(ax2, estims[name] - truth, cmap=\"RdBu\")\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(right=0.85)\n",
    "cbar = fig.colorbar(c1, cax=fig.add_axes([0.9, 0.15, 0.03, 0.7]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6762ff27",
   "metadata": {},
   "source": [
    "#### Exc: Try different values of `Range`.\n",
    "- Run code to re-compute Kriging estimate.\n",
    "- What does setting it to `0.1` cause? What about `100`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90ca081",
   "metadata": {},
   "outputs": [],
   "source": [
    "@ws.interact(Range=(.01, 40))\n",
    "def plot_krieged(Range=1):\n",
    "    vg_params['Range'] = Range\n",
    "    covar_yy = 1 - variogram(dists_yy, **vg_params)\n",
    "    cross_xy = 1 - variogram(dists_xy, **vg_params)\n",
    "    regression_coefficients = sla.solve(covar_yy, cross_xy.T).T\n",
    "\n",
    "    fig, ax = freshfig(num=\"Kriging estimates\")\n",
    "    c1 = contour_plot(ax, regression_coefficients @ observations)\n",
    "    fig.colorbar(c1);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0066e959",
   "metadata": {},
   "source": [
    "# Comments on Kriging\n",
    "Generalizations\n",
    "- Unknown mean (Ordinary Kriging)\n",
    "- Co-Kriging (vector-valued fields)\n",
    "- Trend surfaces (non-stationarity assumptions)\n",
    "\n",
    "Kriging estimators can typically also be derived\n",
    "as **Radial basis function (RBF) interpolation**,\n",
    "or **Gaussian process regression** (GP) regression,\n",
    "providing alternative interpretations.\n",
    "\n",
    "- Kriging is derived by minimizing the variance of linear and unbiased estimators.\n",
    "- RBF interpolation is derived by the explicit desire to fit\n",
    "  N functions to N data points (observations).\n",
    "- GP regression is derived by conditioning (applying Bayes rule)\n",
    "  to the (supposedly) Gaussian distribution of the random field."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "auto:light,ipynb",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
