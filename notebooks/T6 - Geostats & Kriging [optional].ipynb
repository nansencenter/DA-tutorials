{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ad522f",
   "metadata": {},
   "outputs": [],
   "source": [
    "remote = \"https://raw.githubusercontent.com/nansencenter/DA-tutorials\"\n",
    "!wget -qO- {remote}/master/notebooks/resources/colab_bootstrap.sh | bash -s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce795c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from resources import show_answer, interact\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy.random as rnd\n",
    "import scipy.linalg as sla\n",
    "from mpl_tools.misc import nRowCol\n",
    "from mpl_tools.place import freshfig\n",
    "plt.ion();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa798934",
   "metadata": {},
   "source": [
    "# T6 - Spatial statistics (\"geostatistics\") & Kriging\n",
    "\n",
    "Covariances between two (or a few) variables is very well,\n",
    "but if you have not seen it before, the connection between covariances\n",
    "and geophysical (spatial) fields may not be obvious.\n",
    "The purpose of this tutorial is to familiarise you with random (spatial) fields\n",
    "and their estimation.\n",
    "$\n",
    "\\newcommand{\\mat}[1]{{\\mathbf{{#1}}}}\n",
    "\\newcommand{\\bvec}[1]{{\\mathbf{#1}}}\n",
    "\\newcommand{\\Expect}[0]{\\mathbb{E}}\n",
    "\\newcommand{\\NormDist}{\\mathscr{N}}\n",
    "$\n",
    "\n",
    "Set some parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67930eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd.seed(3000)\n",
    "grid1D = np.linspace(0, 1, 21)\n",
    "N = 15  # ensemble size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac1fd0c",
   "metadata": {},
   "source": [
    "## Variograms\n",
    "\n",
    "Denote *physical* location (i.e. a coordinate for 1D/2D/3D space) by $s$.\n",
    "A ***random field***, $Z(s)$ is a function taking random values at each point.\n",
    "Random fields are commonly assumed ***stationary*** (to some degree),\n",
    "meaning that the dependence of $Z(s_{1})$ and $Z(s_{2})$,\n",
    "for any two locations $s_1, s_2$, can be described in terms of the distance separating them, $d = \\| s_{1} - s_{2} \\|$.\n",
    "For now, we will assume that the mean, $\\Expect Z(s)$ is known and constant,\n",
    "leaving the covariance as the most important descriptor.\n",
    "But since the field is stationary, the covariance depends only on the distance,\n",
    "so we can describe the full covariance of the field solely in terms of\n",
    "\"(auto-)***covariance function***\", $C(d) = \\mathbb{Cov}[Z(s_{1}), Z(s_{2})]$.\n",
    "<details style=\"border: 1px solid #aaaaaa; border-radius: 4px; padding: 0.5em 0.5em 0;\">\n",
    "<summary style=\"font-weight: normal; font-style: italic; margin: -0.5em -0.5em 0; padding: 0.5em;\">\n",
    "In practice, geostatistics usually works with a reformulation of $C(d)$ called \"(semi-)<strong>variogram\"</strong>, $\\gamma(d) = C(0) - C(d)$\n",
    "... (optional reading üîç)\n",
    "</summary>\n",
    "The variogram can be defined more generally\n",
    "(allowing for infinite-variance processes, and requiring stationarity of increments, not second-order stationarity)\n",
    "as half the variance of $Z(s_{1}) - Z(s_{2})$.\n",
    "\n",
    "- - -\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c8ac00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def variogram(dists, Range=1, kind=\"Gauss\", nugget=0):\n",
    "    \"\"\"Compute variogram for distance points `dists`.\"\"\"\n",
    "    dists = dists / Range\n",
    "    if kind == \"Spheric\":\n",
    "        gamma = 1.5 * dists - .5 * dists**3\n",
    "        gamma[dists >= 1] = 1\n",
    "    elif kind == \"Expo\":\n",
    "        dists *= 3  # by convention\n",
    "        gamma = 1 - np.exp(-dists)\n",
    "    else:  # \"Gauss\"\n",
    "        dists *= 3  # by convention\n",
    "        gamma = 1 - np.exp(-(dists)**2)\n",
    "    # Include nugget (discontinuity at 0)\n",
    "    gamma *= (1-nugget)\n",
    "    gamma[dists != 0] += nugget\n",
    "    return gamma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7575ba5b",
   "metadata": {},
   "source": [
    "#### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db84032f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact(Range=(.01, 4), nugget=(0.0, 1, .1))\n",
    "def plot_variogram(Range=1, nugget=0):\n",
    "    fig, ax = plt.subplots(figsize=(6, 3))\n",
    "    ax.set_xlim(0, 1)\n",
    "    ax.set_ylim(0, 1)\n",
    "    for i, kind in enumerate([\"Spheric\", \"Expo\", \"Gauss\"]):\n",
    "        gamma = variogram(grid1D, Range, kind, nugget=nugget)\n",
    "        ax.plot(grid1D, gamma, lw=2, color=f\"C{i}\", label=kind)\n",
    "        ax.legend(loc=\"upper left\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8fc946",
   "metadata": {},
   "source": [
    "In order to apply the variogram, we must first compute distances.\n",
    "The following is a fairly efficient implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a62bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist_euclid(A, B):\n",
    "    \"\"\"Compute the l2-norm between each point (row) of A and B\"\"\"\n",
    "    diff = A[:, None, :] - B\n",
    "    d2 = np.sum(diff**2, axis=-1)\n",
    "    return np.sqrt(d2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e80a7a",
   "metadata": {},
   "source": [
    "Now the full covariance (matrix) between any sets of points can be defined by the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514b8dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def covar(coords, **vg_params):\n",
    "    dists = dist_euclid(coords, coords)\n",
    "    return 1 - variogram(dists, **vg_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe149e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = freshfig(\"1D covar\")\n",
    "C = covar(grid1D[:, None], Range=1, kind=\"Gauss\", nugget=1e-3)\n",
    "ax.matshow(C, cmap=\"PuOr\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373e3eec",
   "metadata": {},
   "source": [
    "## Random fields (1D)\n",
    "\n",
    "Gaussian random variables (vectors) are fully specified by their mean and covariance.\n",
    "Once in possession of a covariance matrix, we can use it to sample random variables\n",
    "by multiplying its Cholesky factor (square root) onto standard normal variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b67153",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_gaussian_fields(coords, **vg_params):\n",
    "    \"\"\"Gen. random (Gaussian) fields at `coords` (no structure/ordering required).\"\"\"\n",
    "    C = covar(coords, **vg_params)\n",
    "    L = sla.cholesky(C)\n",
    "    fields = L.T @ rnd.randn(len(L.T), N)\n",
    "    return fields"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec7f769",
   "metadata": {},
   "source": [
    "#### Exc\n",
    "\n",
    "Use the plotting functionality below to\n",
    "explain the effect of `Range` and `nugget`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c100eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = freshfig(\"1D random fields\")\n",
    "fields = sample_gaussian_fields(grid1D[:, None], Range=1, kind=\"Gauss\", nugget=1e-3)\n",
    "ax.plot(grid1D, fields, lw=2);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59bce201",
   "metadata": {},
   "source": [
    "## Random fields (2D)\n",
    "\n",
    "The following sets up a 2d grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6cbfcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid2x, grid2y = np.meshgrid(grid1D, grid1D)\n",
    "grid2x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62220bd7",
   "metadata": {},
   "source": [
    "where `grid2y` has the same shape. However, in the following we will \"flatten\" (a.k.a.\"(un)ravel\", \"vectorize\", or \"string out\") this explicitly 2D grid of nodes into a simple list of points in 2D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d9c99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid2D = np.dstack([grid2x, grid2y]).reshape((-1, 2))\n",
    "grid2D.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91088ee",
   "metadata": {},
   "source": [
    "Importantly, none of the following methods actually assume any structure to the list. So we could also work with a completely irregularly spaced set of points. For example, `sample_gaussian_fields` is immediately applicable also to this 2D case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a3b301",
   "metadata": {},
   "outputs": [],
   "source": [
    "vg_params = dict(Range=1, kind=\"Gauss\", nugget=1e-4)\n",
    "fields = sample_gaussian_fields(grid2D, **vg_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102be5a3",
   "metadata": {},
   "source": [
    "Of course, for plotting purposes, we undo the flattening."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a00108",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contour_plot(ax, field, cmap=\"nipy_spectral\", levels=12, has_obs=True):\n",
    "    field = field.reshape(grid2x.shape)  # undo flattening\n",
    "    if has_obs:\n",
    "        ax.plot(*obs_coo.T, \"ko\", ms=4)\n",
    "        ax.plot(*obs_coo.T, \"yo\", ms=1)\n",
    "    ax.set(aspect=\"equal\", xticks=[0, 1], yticks=[0, 1])\n",
    "    return ax.contourf(field, levels=levels, extent=(0, 1, 0, 1),\n",
    "                       cmap=cmap, vmin=vmin, vmax=vmax)\n",
    "\n",
    "# Fix the color scale for all subsequent `contour_plot`.\n",
    "# Use `None` to re-compute the color scale for each subplot.\n",
    "vmin = fields.min()\n",
    "vmax = fields.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743dce17",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = freshfig(num=\"2D random fields\", figsize=(5, 4),\n",
    "                    nrows=3, ncols=4, sharex=True, sharey=True)\n",
    "\n",
    "for ax, field in zip(axs.ravel(), fields.T):\n",
    "    contour_plot(ax, field, has_obs=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc052b1b",
   "metadata": {},
   "source": [
    "It might be interesting to inspect the covariance matrix in this 2D case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fa9567",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = covar(grid2D, **vg_params)\n",
    "fig, ax = freshfig(\"2D covar\")\n",
    "ax.matshow(C, cmap=\"RdBu\", vmin=0, vmax=1);\n",
    "ax.grid(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed7ad02",
   "metadata": {},
   "source": [
    "## Estimation problem\n",
    "\n",
    "For our estimation target we will use one of the above generated random fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68de60e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "truth = fields.T[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a07ffa",
   "metadata": {},
   "source": [
    "For the observations, we pick some random grid locations for simplicity\n",
    "(even though the methods work also with observations not on grid nodes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae6c607",
   "metadata": {},
   "outputs": [],
   "source": [
    "nObs = 10\n",
    "obs_idx = rnd.randint(0, len(grid2D), nObs)\n",
    "obs_coo = grid2D[obs_idx]\n",
    "observations = truth[obs_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cedb0ab0",
   "metadata": {},
   "source": [
    "## Spatial interpolant methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af230c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-compute re-used objects\n",
    "dists_yy = dist_euclid(obs_coo, obs_coo)\n",
    "dists_xy = dist_euclid(grid2D, obs_coo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4adbab51",
   "metadata": {},
   "outputs": [],
   "source": [
    "estims = dict(Truth=truth)\n",
    "vmin=truth.min()\n",
    "vmax=truth.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5ac9a1",
   "metadata": {},
   "source": [
    "The cells below contain snippets of different spatial interpolation methods,\n",
    "followed by a cell that plots the interpolants.\n",
    "Complete the code snippets.\n",
    "\n",
    "#### Exc: Nearest neighbour interpolation\n",
    "\n",
    "Implement the method [(wikipedia)](https://en.wikipedia.org/wiki/Nearest-neighbor_interpolation).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c562d002",
   "metadata": {},
   "outputs": [],
   "source": [
    "nearest_obs = np.zeros_like(truth, dtype=int)  ### FIX THIS ###\n",
    "estims[\"Nearest-n.\"] = observations[nearest_obs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643eaf1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_answer('nearest neighbour interp')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a570c09",
   "metadata": {},
   "source": [
    "#### Exc: Inverse distance weighting\n",
    "\n",
    "Implement the method [(wikipedia)](https://en.wikipedia.org/wiki/Inverse_distance_weighting).  \n",
    "*Hint: You can ignore the `errstate` line below. It is just used to \"silence warnings\" resulting from division by 0 (whose special case is treated in a cell further down).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10dc2f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "exponent = 3\n",
    "with np.errstate(invalid='ignore', divide='ignore'):\n",
    "    weights = np.zeros_like(dists_xy)  ### FIX THIS ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90968b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_answer('inv-dist weight interp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811b6bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply weights\n",
    "estims[\"Inv-dist.\"] = weights @ observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2932ef49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix singularities\n",
    "estims[\"Inv-dist.\"][obs_idx] = observations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d6c54a",
   "metadata": {},
   "source": [
    "#### Exc: Simple Kriging\n",
    "\n",
    "Implement the method [(wikipedia)](https://en.wikipedia.org/wiki/Kriging#Simple_kriging).  \n",
    "\n",
    "*Hint: use `sla.solve` or `sla.inv` (less recommended)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe15b347",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ANSWER HERE ###\n",
    "covar_yy = ...\n",
    "cross_xy = ...\n",
    "regression_coefficients = weights ### FIX THIS ### -- should be cross_xy / covar_yy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d472d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_answer('Kriging code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618a20b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "estims[\"Kriging\"] = regression_coefficients @ observations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fb879f",
   "metadata": {},
   "source": [
    "### Plot truth, estimates, error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b71840",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = freshfig(num=\"Estimation problem\", figsize=(8, 4), squeeze=False,\n",
    "                    nrows=2, ncols=len(estims), sharex=True, sharey=True)\n",
    "\n",
    "for name, ax1, ax2 in zip(estims, *axs):\n",
    "    ax1.set_title(name)\n",
    "    c1 = contour_plot(ax1, estims[name])\n",
    "    c2 = contour_plot(ax2, estims[name] - truth, cmap=\"RdBu\")\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(right=0.85)\n",
    "cbar = fig.colorbar(c1, cax=fig.add_axes([0.9, 0.15, 0.03, 0.7]))\n",
    "axs[1, 0].set_ylabel(\"Errors\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a87e682",
   "metadata": {},
   "source": [
    "#### Exc: Try different values of `Range`\n",
    "\n",
    "- Run code to re-compute Kriging estimate.\n",
    "- What does setting it to `0.1` cause? What about `100`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31196fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact(Range=(.01, 40))\n",
    "def plot_krieged(Range=1):\n",
    "    vg_params['Range'] = Range\n",
    "    covar_yy = 1 - variogram(dists_yy, **vg_params)\n",
    "    cross_xy = 1 - variogram(dists_xy, **vg_params)\n",
    "    regression_coefficients = sla.solve(covar_yy, cross_xy.T).T\n",
    "\n",
    "    fig, ax = freshfig(num=\"Kriging estimates\")\n",
    "    c1 = contour_plot(ax, regression_coefficients @ observations)\n",
    "    fig.colorbar(c1);\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3392f67",
   "metadata": {},
   "source": [
    "#### Generalizations\n",
    "\n",
    "- Unknown mean (Ordinary Kriging)\n",
    "- Co-Kriging (vector-valued fields)\n",
    "- Trend surfaces (non-stationarity assumptions)\n",
    "\n",
    "## Summary\n",
    "\n",
    "The covariances of random fields can sometimes be described by the autocorrelation function,\n",
    "or equivalently, the (semi-)variogram.\n",
    "Covariances form the basis of a family of (geo-)spatial interpolation and approximation\n",
    "methods known as Kriging, which can also be called/interpreted as\n",
    "**Radial basis function (RBF) interpolation**,\n",
    "**Gaussian process regression** (GP) regression.\n",
    "\n",
    "- Kriging is derived by minimizing the variance of linear and unbiased estimators.\n",
    "- RBF interpolation is derived by the explicit desire to fit\n",
    "  N functions to N data points (observations).\n",
    "- GP regression is derived by conditioning (applying Bayes rule)\n",
    "  to the (supposedly) Gaussian distribution of the random field.\n",
    "\n",
    "### Next: [T7 - Chaos & Lorenz](T7%20-%20Chaos%20%26%20Lorenz%20[optional].ipynb)\n",
    "\n",
    "<a name=\"References\"></a>\n",
    "\n",
    "### References\n",
    "\n",
    "<!--\n",
    "\n",
    "@book{chiles2009geostatistics,\n",
    "  title={Geostatistics: Modeling Spatial Uncertainty},\n",
    "  author={Chil{\\`e}s, J.P. and Delfiner, P.},\n",
    "  isbn={9780470317839},\n",
    "  series={Wiley Series in Probability and Statistics},\n",
    "  url={https://books.google.no/books?id=tZl07WdjYHgC},\n",
    "  year={2009},\n",
    "  publisher={Wiley}\n",
    "}\n",
    "\n",
    "@book{wackernagel2013multivariate,\n",
    "  title={Multivariate Geostatistics: An Introduction with Applications},\n",
    "  author={Wackernagel, H.},\n",
    "  isbn={9783662052945},\n",
    "  year={2013},\n",
    "  publisher={Springer Berlin Heidelberg}\n",
    "}\n",
    "\n",
    "-->"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "ipynb,scripts//py:light,scripts//md"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
