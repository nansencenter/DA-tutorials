{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import resources.workspace as ws\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.ion();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "% START OF MACRO DEF\n",
    "% DO NOT EDIT IN INDIVIDUAL NOTEBOOKS, BUT IN macros.py\n",
    "%\n",
    "\\newcommand{\\Reals}{\\mathbb{R}}\n",
    "\\newcommand{\\Expect}[0]{\\mathbb{E}}\n",
    "\\newcommand{\\NormDist}{\\mathcal{N}}\n",
    "%\n",
    "\\newcommand{\\DynMod}[0]{\\mathscr{M}}\n",
    "\\newcommand{\\ObsMod}[0]{\\mathscr{H}}\n",
    "%\n",
    "\\newcommand{\\mat}[1]{{\\mathbf{{#1}}}}\n",
    "%\\newcommand{\\mat}[1]{{\\pmb{\\mathsf{#1}}}}\n",
    "\\newcommand{\\bvec}[1]{{\\mathbf{#1}}}\n",
    "%\n",
    "\\newcommand{\\trsign}{{\\mathsf{T}}}\n",
    "\\newcommand{\\tr}{^{\\trsign}}\n",
    "\\newcommand{\\tn}[1]{#1}\n",
    "\\newcommand{\\ceq}[0]{\\mathrel{≔}}\n",
    "%\n",
    "\\newcommand{\\I}[0]{\\mat{I}}\n",
    "\\newcommand{\\K}[0]{\\mat{K}}\n",
    "\\newcommand{\\bP}[0]{\\mat{P}}\n",
    "\\newcommand{\\bH}[0]{\\mat{H}}\n",
    "\\newcommand{\\bF}[0]{\\mat{F}}\n",
    "\\newcommand{\\R}[0]{\\mat{R}}\n",
    "\\newcommand{\\Q}[0]{\\mat{Q}}\n",
    "\\newcommand{\\B}[0]{\\mat{B}}\n",
    "\\newcommand{\\C}[0]{\\mat{C}}\n",
    "\\newcommand{\\Ri}[0]{\\R^{-1}}\n",
    "\\newcommand{\\Bi}[0]{\\B^{-1}}\n",
    "\\newcommand{\\X}[0]{\\mat{X}}\n",
    "\\newcommand{\\A}[0]{\\mat{A}}\n",
    "\\newcommand{\\Y}[0]{\\mat{Y}}\n",
    "\\newcommand{\\E}[0]{\\mat{E}}\n",
    "\\newcommand{\\U}[0]{\\mat{U}}\n",
    "\\newcommand{\\V}[0]{\\mat{V}}\n",
    "%\n",
    "\\newcommand{\\x}[0]{\\bvec{x}}\n",
    "\\newcommand{\\y}[0]{\\bvec{y}}\n",
    "\\newcommand{\\z}[0]{\\bvec{z}}\n",
    "\\newcommand{\\q}[0]{\\bvec{q}}\n",
    "\\newcommand{\\br}[0]{\\bvec{r}}\n",
    "\\newcommand{\\bb}[0]{\\bvec{b}}\n",
    "%\n",
    "\\newcommand{\\bx}[0]{\\bvec{\\bar{x}}}\n",
    "\\newcommand{\\by}[0]{\\bvec{\\bar{y}}}\n",
    "\\newcommand{\\barB}[0]{\\mat{\\bar{B}}}\n",
    "\\newcommand{\\barP}[0]{\\mat{\\bar{P}}}\n",
    "\\newcommand{\\barC}[0]{\\mat{\\bar{C}}}\n",
    "\\newcommand{\\barK}[0]{\\mat{\\bar{K}}}\n",
    "%\n",
    "\\newcommand{\\D}[0]{\\mat{D}}\n",
    "\\newcommand{\\Dobs}[0]{\\mat{D}_{\\text{obs}}}\n",
    "\\newcommand{\\Dmod}[0]{\\mat{D}_{\\text{obs}}}\n",
    "%\n",
    "\\newcommand{\\ones}[0]{\\bvec{1}}\n",
    "\\newcommand{\\AN}[0]{\\big( \\I_N - \\ones \\ones\\tr / N \\big)}\n",
    "%\n",
    "% END OF MACRO DEF\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before discussing sequential (time-dependent) inference,\n",
    "we need to know how to estimate unknowns a single data/observations (vector),\n",
    "But before discussing *Bayes' rule*,\n",
    "we should review the most useful of probability distributions, namely\n",
    "# The Gaussian (Normal) distribution\n",
    "\n",
    "Consider the Gaussian random variable $x \\sim \\mathcal{N}(\\mu, \\sigma^2)$.\n",
    "\n",
    "Equivalently, we may write\n",
    "$\\begin{align}\n",
    "p(x) = \\mathcal{N}(x \\mid \\mu, \\sigma^2)\n",
    "\\end{align}$\n",
    "for its probability density function (**pdf**), which is given by\n",
    "$$\\begin{align}\n",
    "\\mathcal{N}(x \\mid \\mu, \\sigma^2) = (2 \\pi \\sigma^2)^{-1/2} e^{-(x-\\mu)^2/2 \\sigma^2} \\, , \\tag{G1}\n",
    "\\end{align}$$\n",
    "for $x \\in (-\\infty, +\\infty)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exc 2.2:** Code it up (complete the code below)! Hints:\n",
    "* Note that `**` is the exponentiation/power operator\n",
    "* $e^x$ is available as `np.exp(x)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf_G1(x, mu, sigma2):\n",
    "    \"Univariate (scalar), Gaussian pdf\"\n",
    "    ### INSERT ANSWER HERE ###\n",
    "    return pdf_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ws.show_answer('pdf_G1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computers generally represent functions numerically by their values on a grid\n",
    "of points (nodes), an approach called \"discretisation\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds = -20, 20\n",
    "N = 201                         # num of grid points\n",
    "grid1d = np.linspace(*bounds,N) # grid\n",
    "dx = grid1d[1] - grid1d[0]      # grid spacing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exc 2.3:** The following code plots the Gaussian pdf you implemented above.\n",
    "Play around with `mu` and `sigma2` to answer these questions:\n",
    " * How does the pdf curve change when `mu` changes?\n",
    " * How does the pdf curve change when you increase `sigma2`?\n",
    " * In a few words, describe the shape of the Gaussian pdf curve. Does this ring a bell for you? *Hint: it should be clear as a bell!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = []\n",
    "@ws.interact(mu=bounds, sigma2=(1, 100), nRemembr=range(12))\n",
    "def plot_pdf_G1(mu=0, sigma2=25, nRemembr=1):\n",
    "    evalud = pdf_G1(grid1d, mu, sigma2)\n",
    "    global values\n",
    "    values = [evalud, *values[:nRemembr]]\n",
    "    colors = plt.get_cmap('jet')(np.linspace(0, 1, nRemembr))\n",
    "    plt.figure(figsize=(6, 2))\n",
    "    for line, c in zip(values, colors):\n",
    "        plt.plot(grid1d, line, c=c)\n",
    "    plt.xlim(*bounds)\n",
    "    plt.ylim(0, .2)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exc 2.4 (optional):** Recall the definition of the expectation (with respect to $p(x)$), namely\n",
    "$$\\Expect [f(x)] \\mathrel{≔} \\int  f(x) \\, p(x) \\, d x \\,,$$\n",
    "where the integral is over the whole domain of $x$.  \n",
    "Recall $p(x) = \\mathcal{N}(x \\mid \\mu, \\sigma^2)$ from eqn (G1).  \n",
    "Use pen, paper, and calculus to show that\n",
    " - (i) the first parameter, $\\mu$, indicates its mean, i.e. that $$\\mu = \\Expect[x] \\,.$$\n",
    "   *Hint: you can rely on the result of (iii)*\n",
    " - (ii) the second parameter, $\\sigma^2>0$, indicates its variance,\n",
    "   i.e. that $$\\sigma^2 = \\mathbb{Var}(x) \\mathrel{≔} \\Expect[(x-\\mu)^2] \\,.$$\n",
    "   *Hint: use $x^2 = x x$ to enable integration by parts.*\n",
    " - (iii) $E[1] = 1$.  \n",
    "   *Hint: Neither Bernouilli and Laplace managed this,\n",
    "   until Gauss did it by focusing on $(E[1])^2$.\n",
    "   For more help, watch [3Blue1Brown](https://www.youtube.com/watch?v=cy8r7WSuT1I&t=3m52s).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ws.show_answer('Gauss integrals')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exc 2.5:** Recall $p(x) = \\mathcal{N}(x \\mid \\mu, \\sigma^2)$ from eqn (G1).  \n",
    "Use pen, paper, and calculus to answer the following questions,  \n",
    "which derive some helpful mnemonics about the distribution.\n",
    "\n",
    " * (i) Find $x$ such that $p(x) = 0$.\n",
    " * (ii) Where is the location of the mode (maximum) of the distribution?  \n",
    "    I.e. find $x$ such that $\\frac{d p}{d x}(x) = 0$.  \n",
    "    *Hint: it's easier to analyse $\\log p(x)$ rather than $p(x)$ itself.*\n",
    " * (iii) Where is the inflection point? I.e. where $\\frac{d^2 p}{d x^2}(x) = 0$.\n",
    " * (iv) Some forms of \"sensitivity analysis\" (a basic form of uncertainty quantification) consist in evaluating $\\frac{d^2 p}{d x^2}(x)$ at the mode.\n",
    "Explain this by reference to the Gaussian shape.\n",
    "*Hint: calculate and interpret $\\frac{d^2 p}{d x^2}(\\mu)$*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The multivariate (i.e. vector) case\n",
    "Here's the pdf of the *multivariate* Gaussian (for any dimension $\\ge 1$):\n",
    "$$\\begin{align}\n",
    "\\NormDist(\\x \\mid  \\mathbf{\\mu}, \\mathbf{\\Sigma})\n",
    "&=\n",
    "|2 \\pi \\mathbf{\\Sigma}|^{-1/2} \\, \\exp\\Big(-\\frac{1}{2}\\|\\x-\\mathbf{\\mu}\\|^2_\\mathbf{\\Sigma} \\Big) \\, , \\tag{GM}\n",
    "\\end{align}$$\n",
    "where $|.|$ represents the matrix determinant,  \n",
    "and $\\|.\\|_\\mathbf{W}$ represents the norm with weighting: $\\|\\x\\|^2_\\mathbf{W} = \\x^T \\mathbf{W}^{-1} \\x$.  \n",
    "In this multivariate case, $\\mathbf{\\Sigma}$ is called the *covariance* (matrix).\n",
    "\n",
    "The following implements this pdf. Take a moment to digest the code, but don't worry if you don't understand it all. Hints:\n",
    " * `@` produces matrix multiplication (`*` in `Matlab`);\n",
    " * `*` produces array multiplication (`.*` in `Matlab`);\n",
    " * `axis=-1` makes `np.sum()` work along the last dimension of an ND-array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.linalg import det, inv\n",
    "\n",
    "def weighted_norm22(points, W):\n",
    "    \"Computes the norm of each vector (row in `points`), weighted by `W`.\"\n",
    "    return np.sum( (points @ inv(W)) * points, axis=-1)\n",
    "\n",
    "def pdf_GM(points, mu, Sigma):\n",
    "    \"pdf -- Gaussian, Multivariate: N(x | mu, Sigma) for each x in `points`.\"\n",
    "    c = np.sqrt(det(2*np.pi*Sigma))\n",
    "    return 1/c * np.exp(-0.5*weighted_norm22(points - mu, Sigma))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code plots the pdf as contour (iso-density) curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "grid2d = np.dstack(np.meshgrid(grid1d, grid1d))\n",
    "\n",
    "@ws.interact(corr=(-1, 1, .05), std_x=(1e-5, 10, 1))\n",
    "def plot_Gaussian_contours(corr=0.7, std_x=1):\n",
    "    # Form covariance matrix (C) from input and some constants\n",
    "    var_x = std_x**2\n",
    "    var_y = 1\n",
    "    cv_xy = np.sqrt(var_x * var_y) * corr\n",
    "    C = 25 * np.array([[var_x, cv_xy],\n",
    "                       [cv_xy, var_y]])\n",
    "    # Evaluate (compute)\n",
    "    density_values = pdf_GM(grid2d, mu=0, Sigma=C)\n",
    "    # Plot\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    height = 1/np.sqrt(det(2*np.pi*C))\n",
    "    plt.contour(grid1d, grid1d, density_values,\n",
    "               levels=np.linspace(1e-4, height, 11))\n",
    "    plt.axis('equal');\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exc 2.7:** How do the contours look? Try to understand why. Cases:\n",
    " * (a) correlation=0.\n",
    " * (b) correlation=0.99.\n",
    " * (c) correlation=0.5. (Note that we've used `plt.axis('equal')`).\n",
    " * (d) correlation=0.5, but with non-equal variances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exc 2.8:** Play the [correlation game](http://guessthecorrelation.com/) (doesn't work right in Chrome) until you get a score (shown as gold coins) of 5 or more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exc 2.9:**\n",
    "* What's the difference between correlation and covariance?\n",
    "* What's the difference between correlation (or covariance) and dependence?  \n",
    "  *Hint: consider this [image](https://en.wikipedia.org/wiki/Pearson_correlation_coefficient#/media/File:Correlation_examples2.svg)*\n",
    "* Does correlation imply causation?\n",
    "* Can you use correlation to in making predictions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exc 2.30 (optional):** Why are we so fond of the Gaussian assumption?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ws.show_answer('Why Gaussian')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next: [Bayesian inference](T3%20-%20Bayesian%20inference.ipynb)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "jupytext": {
   "formats": "ipynb,py"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
