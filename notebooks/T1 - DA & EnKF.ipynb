{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "878ab478",
   "metadata": {},
   "source": [
    "# T1 - Introduction\n",
    "\n",
    "*Copyright (c) 2020, Patrick N. Raanes*\n",
    "\n",
    "This tutorial series introduces *data assimilation (DA)*, beginning with basic mathematical concepts and culminating in your own implementation of the EnKF.\n",
    "Alternatively, the article by [Wikle and Berliner (2007)](#References) is short and nice,\n",
    "while the book by [Asch, Bocquet, and Nodet (2016)](#References) is rigorous and detailed.\n",
    "$\n",
    "\\newcommand{\\DynMod}[0]{\\mathscr{M}}\n",
    "\\newcommand{\\ObsMod}[0]{\\mathscr{H}}\n",
    "\\newcommand{\\mat}[1]{{\\mathbf{{#1}}}}\n",
    "\\newcommand{\\vect}[1]{{\\mathbf{#1}}}\n",
    "\\newcommand{\\x}[0]{\\vect{x}}\n",
    "\\newcommand{\\y}[0]{\\vect{y}}\n",
    "\\newcommand{\\q}[0]{\\vect{q}}\n",
    "\\newcommand{\\r}[0]{\\vect{r}}\n",
    "$\n",
    "\n",
    "## Jupyter\n",
    "\n",
    "The \"document\" you're currently reading is a *Jupyter notebook*.\n",
    "It consists of a sequence of **cells**, which can be either code (Python) or text (markdown).\n",
    "For example, try editing the cell below (double-click it)\n",
    "to insert your name, and running it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abffac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"Batman\"\n",
    "print(\"Hello world! I'm \" + name)\n",
    "for i, c in enumerate(name):\n",
    "    print(i, c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bada75c",
   "metadata": {},
   "source": [
    "Knowing these **keyboard shortcuts** will help you work more efficiently:\n",
    "\n",
    "| Navigate                      | Edit              | Exit           | Run                              | Run & go to next                  |\n",
    "|-------------------------------|-------------------|----------------|----------------------------------|-----------------------------------|\n",
    "| <kbd>↓</kbd> and <kbd>↑</kbd> | <kbd>Enter</kbd>  | <kbd>Esc</kbd> | <kbd>Ctrl</kbd>+<kbd>Enter</kbd> | <kbd>Shift</kbd>+<kbd>Enter</kbd> |\n",
    "\n",
    "Each notebook connects to a background **session (kernel/runtime/interpreter)** of Python, and all code cells in a given notebook are connected, sharing variables, functions, and classes. You can start afresh by clicking `restart` in the top menu bar. The **order** in which you run the cells matters, and from now on,\n",
    "<mark><font size=\"-1\">\n",
    "    the 1st code cell in each tutorial will be the following, which <em>you must run before others</em>. But if you're on Windows, then you must first delete the line starting with `!wget` (which is only really needed when running on Google Colab).\n",
    "</font></mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4828c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "remote = \"https://raw.githubusercontent.com/nansencenter/DA-tutorials\"\n",
    "!wget -qO- {remote}/master/notebooks/resources/colab_bootstrap.sh | bash -s\n",
    "from resources import show_answer, envisat_video"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7544379",
   "metadata": {},
   "source": [
    "## Python\n",
    "\n",
    "There is a huge amount of libraries available in **Python**, including the popular `scipy` and `matplotlib` packages, both with the essential `numpy` library at their core. They're usually abbreviated `sp`, `mpl` (and `plt`), and `np`. Try them out by running the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20e5037",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.ion();\n",
    "\n",
    "# Use numpy's arrays for vectors and matrices. Example constructions:\n",
    "a = np.arange(10) # Alternatively: np.array([0,1,2,3,4,5,6,7,8,9])\n",
    "I = 2*np.eye(10)  # Alternatively: np.diag(2*np.ones(10))\n",
    "\n",
    "print(\"Indexing examples:\")\n",
    "print(\"a        =\", a)\n",
    "print(\"a[3]     =\", a[3])\n",
    "print(\"a[1:3]   =\", a[0:3])\n",
    "print(\"a[-1]    =\", a[-1])\n",
    "print(\"I[:3]    =\", I[:3], sep=\"\\n\")\n",
    "\n",
    "print(\"\\nLinear algebra examples:\")\n",
    "print(\"100+a =\", 100+a)\n",
    "print(\"I@a   =\", I@a)\n",
    "print(\"I*a   =\", I*a, sep=\"\\n\")\n",
    "\n",
    "plt.title(\"Plotting example\")\n",
    "plt.ylabel(\"i $x^2$\")\n",
    "for i in range(4):\n",
    "    plt.plot(i * a**2, label=\"i = %d\"%i)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56bca4ea",
   "metadata": {},
   "source": [
    "These tutorials require that you are able to understand the above code, but not much beyond that.\n",
    "Some exercises will ask you to do some programming, but understanding the pre-written code is also important.\n",
    "The interesting parts of the code can all be found in the notebooks themselves\n",
    "(as opposed to being hidden away via imports).\n",
    "Beware, however, that it is not generally production-ready.\n",
    "For example, it overuses global variables, and is lacking in vectorisation,\n",
    "generally for the benefit of terseness and simplicity.\n",
    "\n",
    "## Dynamical and observational models\n",
    "\n",
    "What is a ***model***?\n",
    "In the broadest sense, a model is a *simplified representation* of something.\n",
    "Whether it be some laws of nature, or comprising of a set of empirical or statistical relations,\n",
    "the underlying aim is usually that of making **predictions** of some sort.\n",
    "A convenient language for this purpose is mathematics,\n",
    "in which case the model consists of a set of equations, often differential.\n",
    "\n",
    "We will mainly be concerned with models of **dynamical systems**, meaning *stuff that changes in time*.\n",
    "The \"stuff\", denoted $\\x_k$ for time index $k$, will be referred to as ***state*** variables/vectors.\n",
    "Regardless of sophistication or how many PhDs worked on coding it up as a computer simulation program,\n",
    "the ***dynamical model*** will henceforth be represented simply as the *function* $\\DynMod_k$\n",
    "that **forecasts** (predicts) the state at time $k+1$ from $\\x_k$.\n",
    "\n",
    "Examples include\n",
    "\n",
    "- (a) Laws of motion and gravity (Newton, Einstein)\n",
    "- (b) Epidemic (SEIR) and predator-prey (Lotka-Volterra)\n",
    "- (c) Weather/climate forecasting (Navier–Stokes + thermodynamics + ideal gas law + radiation + cloud microphysics + BCs)\n",
    "- (d) Petroleum reservoir flow (Multiphase Darcy's law + ...)\n",
    "- (e) Chemical and biological kinetics (Arrhenius, Michaelis-Menten, Mass Action Law)\n",
    "- (f) Traffic flow (Lighthill-Whitham-Richards)\n",
    "- (g) Sports rating (Elo, Glicko, TrueSkill)\n",
    "- (h) Financial pricing (Black-Scholes)\n",
    "\n",
    "**Exc (optional) -- state variables:**  \n",
    "\n",
    "- For the above model examples above that you are familiar with, list the elements of the state variable.\n",
    "\n",
    "- Generally speaking, do you think\n",
    "  - the ordering of the elements/components matters?\n",
    "  - the state vector needs to be of fixed length, or can it change over time?\n",
    "  - it is problematic if we include more variables than needed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34ac0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_answer('state variables')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7829c6f",
   "metadata": {},
   "source": [
    "A model is usually assessed in terms of (some measure of) skill of prediction,\n",
    "as expressed by the following maxim.\n",
    "\n",
    "> All models are wrong, but some are useful — [George E. P. Box](https://en.wikipedia.org/wiki/All_models_are_wrong)\n",
    "\n",
    "**Exc (optional) -- model error:**  \n",
    "For each of model examples above, select the shortcomings (below) that seem relevant.\n",
    "\n",
    "1. Inaccurate at relatively high speeds\n",
    "1. Extreme events do not conform to statistical assumptions\n",
    "1. Assumes closed systems, ignoring external influences,\n",
    "   except for poorly specified boundary conditions and forcings\n",
    "1. Assumes equilibrium or steady-state when systems are inherently dynamic\n",
    "1. Lack of demographic and/or geographic resolution.\n",
    "1. Continuity is an approximation\n",
    "1. Oversimplification of complex interactions and feedbacks\n",
    "1. Incompatibility with quantum dynamics\n",
    "1. Insufficient spatial or temporal resolution upon discretization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aea7fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_answer('model error')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c417beed",
   "metadata": {},
   "source": [
    "Taking the quoted advice to heart, in data assimilation it is common to assume that\n",
    "the difference between the true evolution and that suggested by the model alone is explained\n",
    "by a random (stochastic) noise term, $\\q_k$, with a known distribution, i.e.\n",
    "\n",
    "$$ \\x_{k+1} = \\DynMod_k(\\x_k) + \\q_k \\,. \\tag{DynMod} $$\n",
    "\n",
    "However, a good model (i.e. $\\q \\approx 0$) is not enough to ensure good predictions, because\n",
    "\n",
    "> Garbage in, garbage out ([GIGO](https://en.wikipedia.org/wiki/Garbage_in,_garbage_out))\n",
    "\n",
    "In other words, we also need accurate initial conditions,\n",
    "i.e. a good estimate of $\\x_k$.\n",
    "This is known as the ***forecast initialisation*** problem.\n",
    "It may seem obvious and trifling if $\\x_k$ is some experimental condition that is\n",
    "completely in our control, or if $\\x_k$ is a computable steady-state condition of the system\n",
    "(to wit, typically in both cases, $k=0$).\n",
    "But it is not so easy to determine $\\x_k$ when it is the state of an ongoing, constantly-evolving process,\n",
    "and/or if we have only very limited observations of it.\n",
    "For example, consider the case of numerical weather prediction (NWP).\n",
    "Clearly, in order to launch the numerical simulator (model), $\\DynMod_k$,\n",
    "to forecast (predict) *tomorrow*'s weather,\n",
    "we initially need to know *today*'s state of the atmosphere (wind, pressure, density and temperature)\n",
    "at each grid point in the model.\n",
    "Yet despite the vast increase in data since the advent of weather satellites in the 1970s,\n",
    "most parts of the globe are (at any given moment) unobserved.\n",
    "Moreover, the ***measurement/observation data*** available to us, $\\y_k$, are not generally a \"direct observation\"\n",
    "of quantities in the state vector, but rather some function, i.e. model thereof, $\\ObsMod_{\\!k}$\n",
    "(in the case of satellite radiances: an integral along the vertical column at some lat/long location,\n",
    "or even a more complicated radiative transfer model).\n",
    "Finally, since any measurement is somewhat imprecise,\n",
    "we include an observation noise, $\\r_k$, in our conception of the measuring process, i.e.\n",
    "\n",
    "$$ \\y_k = \\ObsMod_{\\!k}(\\x_k) + \\r_k \\,. \\tag{ObsMod} $$\n",
    "\n",
    "**Exc (optional) -- observation examples:**  \n",
    "For each of the above dynamical model examples, suggest 1 or more observation kinds (i.e. what will $\\y$ consist of?)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617f94bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_answer('obs examples')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1caf62",
   "metadata": {},
   "source": [
    "## Data + Models = ❤️\n",
    "\n",
    "The above complications make the forecast initialisation problem daunting.\n",
    "Fortunately we have another source of information on $\\x_k$: yesterday's (or the previous) forecast.\n",
    "As we will see, using it as a \"prior\" in the estimation of $\\x_k$ will implicitly\n",
    "incorporate the information from *previous* observations, $\\y_1, \\ldots, \\y_{k-1}$,\n",
    "on top of the \"incoming\" one, $\\y_k$.\n",
    "Thus, model forecasts help out the data, $\\y_k$, in the estimation of $\\x_k$,\n",
    "which in turn improve the forecast of $\\x_{k+1}$, and so on in a *virtuous cycle* of improved estimation and prediction (❤️).\n",
    "\n",
    "The *cyclic* computational procedure outlined above for the sequence of forecast initialisation problems is known as **filtering**.\n",
    "More generally, the theory of **state estimation** (a.k.a. **sequential inference**)\n",
    "also includes the techniques of **smoothing** (the estimation of *earlier* states)\n",
    "and — as an add-on — the estimation of parameters (uncertain/unknown quantities that do *not* change in time).\n",
    "State estimation can be said to generalize [time series estimation](https://www.google.no/books/edition/Time_Series_Analysis_by_State_Space_Meth/XRCu5iSz_HwC)\n",
    "and [signal processing](https://ocw.mit.edu/courses/6-011-introduction-to-communication-control-and-signal-processing-spring-2010/0009cae26d5218d6ebae14297d111325_MIT6_011S10_chap04.pdf),\n",
    "by allowing for multivariate, hidden states (partially observed, or only through the operator $\\ObsMod$),\n",
    "and adding the sophistication (and computational burden) of the predictive model $\\DynMod$.\n",
    "\n",
    "The most famous state estimation technique is the ***Kalman filter (KF)***,\n",
    "which was developed to steer the Apollo mission rockets to the moon.\n",
    "To wit, in guidance systems, the *state variable* (vector) consists of at least 6 elements: 3 for the current position and 3 for velocity, whose trajectories we wish to track in time. More sophisticated systems can also include acceleration and/or angular quantities. The *dynamical model* then consists of the fact that displacement is the time integral of the velocity, while the velocity is the integral of acceleration, which can be determined from Newton/Einstein's laws of gravity as well and the steering controls of the vessel. The noisy *observations* can come from altimetry, sextants, speedometers, compass readings, accelerometers, gyroscopes, or fuel-gauges. The essential point is that we have an *observational model* predicting the observations from the state. For example, the altimeter model is simply the function that selects the $z$ coordinate from the state vector, while the force experienced by an accelerometer can be modelled by Newton's second law of motion.\n",
    "\n",
    "<img align=\"right\" width=\"400\" src=\"./resources/DA_bridges.jpg\" alt='DA \"bridges\" data and models.'/>\n",
    "\n",
    "In the context of *large* dynamical systems, especially in geoscience (climate, ocean, hydrology, petroleum)\n",
    "state estimation is known as **data assimilation** (DA),\n",
    "and is seen as a \"bridge\" between data and models,\n",
    "as illustrated on the right (source: [AICS-Riken](https://aics.riken.jp/en)).\n",
    "For example, in weather applications, the dynamical model is an atmospheric fluid-mechanical simulator, the state variable consists of the fields of pressure, humidity, and wind quantities discretized on a grid,\n",
    "and the observations may come from satellite or weather stations.\n",
    "\n",
    "But when the KF was first proposed for DA (specifically, weather forecasting), the idea seemed ludicrous due to\n",
    "several technical challenges in DA compared to \"classic\" state estimation:\n",
    "\n",
    "- size of data and models;\n",
    "- nonlinearity of models;\n",
    "- sparsity and inhomogeneous-ness of data.\n",
    "\n",
    "Some of these challenges may be recognized in the video below. Can you spot them?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a42cd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "envisat_video()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4729997",
   "metadata": {},
   "source": [
    "## The ensemble Kalman filter (EnKF)\n",
    "\n",
    "The EnKF is a Monte-Carlo formulation of the KF\n",
    "resulting in a simple and versatile method for DA,\n",
    "that manages (to some extent) to deal with the above challenges in DA.\n",
    "For those familiar with the method of 4D-Var, **further advantages of the EnKF** include it being:\n",
    "\n",
    "- Non-invasive: the models are treated as black boxes, and no explicit Jacobian is required.\n",
    "- Bayesian:\n",
    "  - provides ensemble of possible realities;\n",
    "    - arguably the most practical form of \"uncertainty quantification\";\n",
    "    - ideal way to initialize \"ensemble forecasts\";\n",
    "  - uses \"flow-dependent\" background covariances in the analysis.\n",
    "- Embarrassingly parallelizable:\n",
    "  - distributed across realizations for model forecasting;\n",
    "  - distributed across local domains for observation analysis.\n",
    "\n",
    "## DAPPER example\n",
    "\n",
    "This tutorial builds on the underlying package, [DAPPER](https://github.com/nansencenter/DAPPER), made for academic research in DA and its dissemination. For example, the code below is taken from  `DAPPER/example_1.py`. It illustrates DA on a small toy problem. At the end of these tutorials, you should be able to reproduce (from the ground up) this type of experiment.\n",
    "\n",
    "Run the cells in order and try to interpret the output.\n",
    "<mark><font size=\"-1\">\n",
    "<em>Don't worry</em> if you can't understand what's going on — we will discuss it later throughout the tutorials.\n",
    "</font></mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eada171d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dapper as dpr\n",
    "import dapper.da_methods as da\n",
    "\n",
    "# Load experiment setup: the hidden Markov model (HMM)\n",
    "from dapper.mods.Lorenz63.sakov2012 import HMM\n",
    "HMM.tseq.T = 30  # shorten experiment\n",
    "\n",
    "# Simulate synthetic truth (xx) and noisy obs (yy)\n",
    "xx, yy = HMM.simulate()\n",
    "\n",
    "# Specify a DA method configuration (\"xp\" is short for \"experiment\")\n",
    "# xp = da.OptInterp()\n",
    "# xp = da.Var3D()\n",
    "# xp = da.ExtKF(infl=90)\n",
    "xp = da.EnKF('Sqrt', N=10, infl=1.02, rot=True)\n",
    "# xp = da.PartFilt(N=100, reg=2.4, NER=0.3)\n",
    "\n",
    "# Assimilate yy, knowing the HMM; xx is used to assess the performance\n",
    "xp.assimilate(HMM, xx, yy)\n",
    "\n",
    "# #### Average the time series of various statistics\n",
    "# print(xp.stats)  # ⇒ long printout\n",
    "xp.stats.average_in_time()\n",
    "\n",
    "print(xp.avrgs.tabulate(['rmse.a', 'rmv.a']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65df0a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "xp.stats.replay()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16807f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some more diagnostics\n",
    "if False:\n",
    "    import dapper.tools.viz as viz\n",
    "    viz.plot_rank_histogram(xp.stats)\n",
    "    viz.plot_err_components(xp.stats)\n",
    "    viz.plot_hovmoller(xx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615e4fa2",
   "metadata": {},
   "source": [
    "## Vocabulary exercises\n",
    "\n",
    "**Exc -- Word association:**\n",
    "Group the words below into 3 groups of similar meaning.\n",
    "\n",
    "`Sample, Random, Measurements, Ensemble, Data, Stochastic, Monte-Carlo, Observations, Set of draws`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d80e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_answer('thesaurus 1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc4c604",
   "metadata": {},
   "source": [
    "- \"The answer\" is given from the perspective of DA. Do you agree with it?\n",
    "- Can you describe the (important!) nuances between the similar words?\n",
    "\n",
    "**Exc (optional) -- Word association 2:**\n",
    "Also group (and nuance!) these words, by filling in the `x`s in the list below.\n",
    "\n",
    "`Inverse problems, Operator, Sample point, Transform(ation), Knowledge, Relation, Probability, Mapping, Particle, Sequential, Inversion, Realization, Relative frequency, Information, Iterative, Estimate, Estimation, Single draw, Serial, Regression, Model, Fitting, Uncertainty`\n",
    "\n",
    "- Statistical inference, x, x, x, x, x\n",
    "- Ensemble member, x, x, x, x\n",
    "- Quantitative belief, x, x, x, x, x, x\n",
    "- Recursive, x, x, x\n",
    "- Function, x, x, x, x, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6431a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_answer('thesaurus 2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d394ce",
   "metadata": {},
   "source": [
    "**Exc (optional) -- intro discussion:** Prepare to discuss the following questions. Use any tool at your disposal.\n",
    "\n",
    "- (a) What is DA?\n",
    "- (b) What is the difference between \"state variables\" and \"parameters\"?\n",
    "- (c) What are \"prognostic\" variables?\n",
    "  How do they differ from \"diagnostic\" variables?\n",
    "- (d) $k$ is the time index, but what determines the times they correspond to?\n",
    "- (e) Is DA a science, an engineering art, or a dark art?\n",
    "- (f) What is the point of \"Hidden Markov Models\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87b3af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_answer('Discussion topics 1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f98fca",
   "metadata": {},
   "source": [
    "### Next: [T2 - Gaussian distribution](T2%20-%20Gaussian%20distribution.ipynb)\n",
    "\n",
    "<a name=\"References\"></a>\n",
    "\n",
    "### References\n",
    "\n",
    "<!--\n",
    "@article{wikle2007bayesian,\n",
    "    title={A {B}ayesian tutorial for data assimilation},\n",
    "    author={Wikle, C. K. and Berliner, L. M.},\n",
    "    journal={Physica D: Nonlinear Phenomena},\n",
    "    volume={230},\n",
    "    number={1-2},\n",
    "    pages={1--16},\n",
    "    year={2007},\n",
    "    publisher={Elsevier}\n",
    "}\n",
    "\n",
    "@book{asch2016data,\n",
    "    title={Data assimilation: methods, algorithms, and applications},\n",
    "    author={Asch, Mark and Bocquet, Marc and Nodet, Ma{\\\"e}lle},\n",
    "    year={2016},\n",
    "    doi={10.1137/1.9781611974546},\n",
    "    series={Fundamentals of Algorithms},\n",
    "    pages={xvii+295},\n",
    "    edition = {},\n",
    "    address = {Philadelphia, PA},\n",
    "    publisher={SIAM}\n",
    "}\n",
    "-->\n",
    "\n",
    "- **Wikle and Berliner (2007)**:\n",
    "  C. K. Wikle and L. M. Berliner, \"A Bayesian tutorial for data assimilation\", Physica D, 2007.\n",
    "- **Asch, Bocquet, and Nodet (2016)**:\n",
    "  Mark Asch, Marc Bocquet, and Maëlle Nodet, \"Data assimilation: methods, algorithms, and applications\", 2016."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,scripts//py:light,scripts//md"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
