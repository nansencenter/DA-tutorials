{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T1 - Data assimilation (DA) & the ensemble Kalman filter (EnKF)\n",
    "*Copyright (c) 2020, Patrick N. Raanes\n",
    "$\n",
    "% START OF MACRO DEF\n",
    "% DO NOT EDIT IN INDIVIDUAL NOTEBOOKS, BUT IN macros.py\n",
    "%\n",
    "\\newcommand{\\Reals}{\\mathbb{R}}\n",
    "\\newcommand{\\Expect}[0]{\\mathbb{E}}\n",
    "\\newcommand{\\NormDist}{\\mathcal{N}}\n",
    "%\n",
    "\\newcommand{\\DynMod}[0]{\\mathscr{M}}\n",
    "\\newcommand{\\ObsMod}[0]{\\mathscr{H}}\n",
    "%\n",
    "\\newcommand{\\mat}[1]{{\\mathbf{{#1}}}}\n",
    "%\\newcommand{\\mat}[1]{{\\pmb{\\mathsf{#1}}}}\n",
    "\\newcommand{\\bvec}[1]{{\\mathbf{#1}}}\n",
    "%\n",
    "\\newcommand{\\trsign}{{\\mathsf{T}}}\n",
    "\\newcommand{\\tr}{^{\\trsign}}\n",
    "\\newcommand{\\tn}[1]{#1}\n",
    "\\newcommand{\\ceq}[0]{\\mathrel{≔}}\n",
    "%\n",
    "\\newcommand{\\I}[0]{\\mat{I}}\n",
    "\\newcommand{\\K}[0]{\\mat{K}}\n",
    "\\newcommand{\\bP}[0]{\\mat{P}}\n",
    "\\newcommand{\\bH}[0]{\\mat{H}}\n",
    "\\newcommand{\\bF}[0]{\\mat{F}}\n",
    "\\newcommand{\\R}[0]{\\mat{R}}\n",
    "\\newcommand{\\Q}[0]{\\mat{Q}}\n",
    "\\newcommand{\\B}[0]{\\mat{B}}\n",
    "\\newcommand{\\C}[0]{\\mat{C}}\n",
    "\\newcommand{\\Ri}[0]{\\R^{-1}}\n",
    "\\newcommand{\\Bi}[0]{\\B^{-1}}\n",
    "\\newcommand{\\X}[0]{\\mat{X}}\n",
    "\\newcommand{\\A}[0]{\\mat{A}}\n",
    "\\newcommand{\\Y}[0]{\\mat{Y}}\n",
    "\\newcommand{\\E}[0]{\\mat{E}}\n",
    "\\newcommand{\\U}[0]{\\mat{U}}\n",
    "\\newcommand{\\V}[0]{\\mat{V}}\n",
    "%\n",
    "\\newcommand{\\x}[0]{\\bvec{x}}\n",
    "\\newcommand{\\y}[0]{\\bvec{y}}\n",
    "\\newcommand{\\z}[0]{\\bvec{z}}\n",
    "\\newcommand{\\q}[0]{\\bvec{q}}\n",
    "\\newcommand{\\br}[0]{\\bvec{r}}\n",
    "\\newcommand{\\bb}[0]{\\bvec{b}}\n",
    "%\n",
    "\\newcommand{\\bx}[0]{\\bvec{\\bar{x}}}\n",
    "\\newcommand{\\by}[0]{\\bvec{\\bar{y}}}\n",
    "\\newcommand{\\barB}[0]{\\mat{\\bar{B}}}\n",
    "\\newcommand{\\barP}[0]{\\mat{\\bar{P}}}\n",
    "\\newcommand{\\barC}[0]{\\mat{\\bar{C}}}\n",
    "\\newcommand{\\barK}[0]{\\mat{\\bar{K}}}\n",
    "%\n",
    "\\newcommand{\\D}[0]{\\mat{D}}\n",
    "\\newcommand{\\Dobs}[0]{\\mat{D}_{\\text{obs}}}\n",
    "\\newcommand{\\Dmod}[0]{\\mat{D}_{\\text{obs}}}\n",
    "%\n",
    "\\newcommand{\\ones}[0]{\\bvec{1}}\n",
    "\\newcommand{\\AN}[0]{\\big( \\I_N - \\ones \\ones\\tr / N \\big)}\n",
    "%\n",
    "% END OF MACRO DEF\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jupyter\n",
    "The \"document\" you're currently reading is a *Jupyter notebook*.\n",
    "As you can see, it consists of a sequence of **cells**,\n",
    "which can be code (Python) or text (markdown).\n",
    "For example, try editing the cell below (double-click it)\n",
    "to insert your name, and running it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"Batman\"\n",
    "print(\"Hello world! I'm \" + name)\n",
    "for i, c in enumerate(name):\n",
    "    print(i, c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will likely be more efficient if you know these **keyboard shortcuts**:\n",
    "\n",
    "| Navigate                      | Edit              | Exit           | Run                              | Run & go to next                  |\n",
    "|-------------------------------|-------------------|----------------|----------------------------------|-----------------------------------|\n",
    "| <kbd>↓</kbd> and <kbd>↑</kbd> | <kbd>Enter</kbd>  | <kbd>Esc</kbd> | <kbd>Ctrl</kbd>+<kbd>Enter</kbd> | <kbd>Shift</kbd>+<kbd>Enter</kbd> |\n",
    "\n",
    "Actually, a notebook connects to a background **session (kernel/runtime/interpreter)** of Python, and all of the code cells (in a given notebook) are connected, meaning that they share variables, functions, and classes. You can start afresh by clicking `restart` somewhere in the top menu bar. The **order** in which you run the cells matters, and from now on,\n",
    "<mark><font size=\"-1\">\n",
    "    the 1st code cell in each tutorial will be the following, which <em>you must run before others</em>:\n",
    "</font></mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import resources.workspace as ws"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python\n",
    "\n",
    "There is a huge amount of libraries available in **Python**, including the popular `scipy` and `matplotlib` packages, both with the essential `numpy` library at their core. They're usually abbreviated `sp`, `mpl` (and `plt`), and `np`. Try them out by running the following cell. These tutorials require that you are able to understand the code below, but not too much beyond that (the more advanced programming parts, which mainly concerns plotting, are pre-written)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.ion();\n",
    "\n",
    "# Use numpy's arrays for vectors and matrices. Example constructions:\n",
    "a = np.arange(10) # Alternatively: np.array([0,1,2,3,4,5,6,7,8,9])\n",
    "I = 2*np.eye(10)  # Alternatively: np.diag(2*np.ones(10))\n",
    "\n",
    "print(\"Indexing examples:\")\n",
    "print(\"a        =\", a)\n",
    "print(\"a[3]     =\", a[3])\n",
    "print(\"a[0:3]   =\", a[0:3])\n",
    "print(\"a[:3]    =\", a[:3])\n",
    "print(\"a[3:]    =\", a[3:])\n",
    "print(\"a[-1]    =\", a[-1])\n",
    "print(\"I[:3,:3] =\", I[:3,:3], sep=\"\\n\")\n",
    "\n",
    "print(\"\\nLinear algebra examples:\")\n",
    "print(\"100+a =\", 100+a)\n",
    "print(\"I@a   =\", I@a)\n",
    "print(\"I*a   =\", I*a, sep=\"\\n\")\n",
    "\n",
    "plt.title(\"Plotting example\")\n",
    "plt.ylabel(\"i $x^2$\")\n",
    "for i in range(4):\n",
    "    plt.plot(i * a**2, label=\"i = %d\"%i)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data assimilation (DA)\n",
    "\n",
    "**State estimation** (a.k.a. **sequential inference**)\n",
    "is the estimation of unknown/uncertain quantities of **dynamical systems**\n",
    "based on imprecise (noisy) data/observations. This is similar to time series estimation and signal processing,\n",
    "but focuse on the case where we have a good (skillful) predictive model of the dynamical system,\n",
    "so that we can relate information (estimates) of its *state* at one time to another.\n",
    "\n",
    "For example, in guidance systems, the *state variable* (vector) consists of at least 6 elements: 3 for the current position and 3 for velocity, whose trajectories we wish to track in time. More sophisticated systems can also include acceleration and/or angular quantities. The *dynamicl model* then consists of the fact that displacement is the time integral of the velocity, while the velocity is the integral of acceleration. The noisy *observations* can come from altimetry, sextants, speedometers, compass readings, accelerometers, gyroscopes, or fuel-gauges. The essential point is that we have an *observational model* predicting the observations from the state. For example, the altimeter model is simply the function that selects the $z$ coordinate from the state vector, while the force experienced by an accelerometer can be modelled by Newton's second law of motion, $F = m a$.\n",
    "\n",
    "In the context of large dynamical systems, especially in geoscience\n",
    "(climate, ocean, hydrology, petroleum)\n",
    "state estimation is known as **data assimilation** (DA),\n",
    "and is thought of as a \"bridge\" between data and models,\n",
    "as illustrated on the right (source: <a href=\"http://www.aics.riken.jp\">www.aics.riken.jp</a>)\n",
    "<img align=\"right\" width=\"400\" src=\"./resources/DA_bridges.jpg\" alt='DA \"bridges\" data and models.'/>.\n",
    "For example, in weather applications, the dynamical model is an atmospheric fluid-mechanical simulator, the state variable consists of the fields of pressure, humidity, and wind quanities discretized on a grid,\n",
    "and the observations may come from satellite or weather stations.\n",
    "\n",
    "The most famous state estimation techniques is the ***Kalman filter (KF)***, which was developed to steer the Apollo mission rockets to the moon. The KF also has applications outside of control systems, such as speech recognition, video tracking, finance. But when it was first proposed to apply the KF to DA (specifically, weather forecasting), the idea sounded ludicrous because of some severe **technical challenges in DA (vs. \"classic\" state estimation)**:\n",
    " * size of data and models;\n",
    " * nonlinearity of models;\n",
    " * sparsity and inhomogeneous-ness of data.\n",
    "\n",
    "Some of these challenges may be recognized in the video below. Can you spot them?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws.envisat_video()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The EnKF is:\n",
    "an ensemble (Monte-Carlo) formulation of the KF\n",
    "that manages (fairly well) to deal with the above challenges in DA.\n",
    "\n",
    "For those familiar with the method of 4D-Var, **further advantages of the EnKF** include it being:\n",
    " * Non-invasive: the models are treated as black boxes, and no explicit Jacobian is required.\n",
    " * Bayesian:\n",
    "   * provides ensemble of possible realities;\n",
    "       - arguably the most practical form of \"uncertainty quantification\";\n",
    "       - ideal way to initialize \"ensemble forecasts\";\n",
    "   * uses \"flow-dependent\" background covariances in the analysis.\n",
    " * Embarrassingly parallelizable:\n",
    "   * distributed across realizations for model forecasting;\n",
    "   * distributed across local domains for observation analysis.\n",
    "\n",
    "The rest of this tutorial provides an EnKF-centric presentation of DA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DAPPER example\n",
    "This tutorial builds on the underlying package, DAPPER, made for academic research in DA and its dissemination. For example, the code below is taken from  `DAPPER/example_1.py`. It illustrates DA on a small toy problem. At the end of these tutorials, you should be able to reproduce (from the ground up) this type of experiment.\n",
    "\n",
    "Run the cells in order and try to interpret the output.\n",
    "<mark><font size=\"-1\">\n",
    "<em>Don't worry</em> if you can't understand what's going on -- we will discuss it later throughout the tutorials.\n",
    "</font></mark>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dapper as dpr\n",
    "import dapper.da_methods as da\n",
    "\n",
    "# Load experiment setup: the hidden Markov model (HMM)\n",
    "from dapper.mods.Lorenz63.sakov2012 import HMM\n",
    "HMM.tseq.T = 30  # shorten experiment\n",
    "\n",
    "# Simulate synthetic truth (xx) and noisy obs (yy)\n",
    "xx, yy = HMM.simulate()\n",
    "\n",
    "# Specify a DA method configuration (\"xp\" is short for \"experiment\")\n",
    "# xp = da.OptInterp()\n",
    "# xp = da.Var3D()\n",
    "# xp = da.ExtKF(infl=90)\n",
    "xp = da.EnKF('Sqrt', N=10, infl=1.02, rot=True)\n",
    "# xp = da.PartFilt(N=100, reg=2.4, NER=0.3)\n",
    "\n",
    "# Assimilate yy, knowing the HMM; xx is used to assess the performance\n",
    "xp.assimilate(HMM, xx, yy)\n",
    "\n",
    "# #### Average the time series of various statistics\n",
    "# print(xp.stats)  # ⇒ long printout\n",
    "xp.stats.average_in_time()\n",
    "\n",
    "print(xp.avrgs.tabulate(['rmse.a', 'rmv.a']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xp.stats.replay()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some more diagnostics\n",
    "if False:\n",
    "    import dapper.tools.viz as viz\n",
    "    viz.plot_rank_histogram(xp.stats)\n",
    "    viz.plot_err_components(xp.stats)\n",
    "    viz.plot_hovmoller(xx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vocabulary exercises\n",
    "**Exc 1.2:** Word association.\n",
    "Fill in the `X`'s in the table to group the words according to meaning.\n",
    "\n",
    "`Filtering, Sample, Random, Measurements, Forecast initialisation, Monte-Carlo, Observations, Set of draws`\n",
    "\n",
    "```\n",
    "Filtering     Ensemble      Stochastic     Data\n",
    "-----------------------------------------------\n",
    "X             X             X              X\n",
    "              X             X              X\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ws.show_answer('thesaurus 1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* \"The answer\" is given from the perspective of DA. Do you agree with it?\n",
    "* Can you describe the (important!) nuances between the similar words?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exc 1.3 (optional):** Word association 2.\n",
    "Group these words:\n",
    "\n",
    "`Inverse problems, Sample point, Knowledge, Probability, Particle, Sequential, Inversion, Realization, Relative frequency, Information, Iterative, Estimate, Estimation, Single draw, Serial, Regression, Fitting, Uncertainty`\n",
    "\n",
    "\n",
    "    Statistical inference    Ensemble member     Quantitative belief    Recursive\n",
    "    -----------------------------------------------------------------------------\n",
    "    X                        X                   X                      X\n",
    "    X                        X                   X                      X\n",
    "    X                        X                   X                      X\n",
    "    X                        X                   X\n",
    "    X                                            X\n",
    "                                                 X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ws.show_answer('thesaurus 2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exc 1.5 (optional):** Prepare to discuss the following questions. Use any tool at your disposal.\n",
    "* (a) What is DA?\n",
    "* (b) What are \"state variables\"? How do they differ from parameters?\n",
    "* (c) What is a \"dynamical system\"?\n",
    "* (d) Is DA a science, an engineering art, or a dark art?\n",
    "* (e) What is the point of \"Hidden Markov Models\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ws.show_answer('Discussion topics 1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next: [T2 - Gaussian distribution](T2%20-%20Gaussian%20distribution.ipynb)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "jupytext": {
   "formats": "ipynb,py"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
